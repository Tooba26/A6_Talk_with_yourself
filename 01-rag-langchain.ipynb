{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "# Retrieval-Augmented generation (RAG)\n",
    "\n",
    "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
    "\n",
    "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "\n",
    "<img src=\"../figures/RAG-process.png\" >\n",
    "\n",
    "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
    "\n",
    "1. Prompt\n",
    "2. Retrieval\n",
    "3. Memory\n",
    "4. Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain==0.0.350\n",
      "  Using cached langchain-0.0.350-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/tljh/user/lib/python3.12/site-packages (from langchain==0.0.350) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/tljh/user/lib/python3.12/site-packages (from langchain==0.0.350) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from langchain==0.0.350) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from langchain==0.0.350) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/tljh/user/lib/python3.12/site-packages (from langchain==0.0.350) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.350)\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain==0.0.350)\n",
      "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.350)\n",
      "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from langchain==0.0.350) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/tljh/user/lib/python3.12/site-packages (from langchain==0.0.350) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from langchain==0.0.350) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from langchain==0.0.350) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/tljh/user/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/tljh/user/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.350) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.350)\n",
      "  Using cached langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Using cached langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Using cached langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Using cached langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Using cached langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Using cached langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Using cached langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
      "  Using cached langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Using cached langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Using cached langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "  Using cached langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain==0.0.350)\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/tljh/user/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (4.7.0)\n",
      "  Using cached langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.350)\n",
      "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/tljh/user/lib/python3.12/site-packages (from pydantic<3,>=1->langchain==0.0.350) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/tljh/user/lib/python3.12/site-packages (from pydantic<3,>=1->langchain==0.0.350) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/tljh/user/lib/python3.12/site-packages (from pydantic<3,>=1->langchain==0.0.350) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.0.350) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.0.350) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.0.350) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.0.350) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.350) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/tljh/user/lib/python3.12/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain==0.0.350) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (1.0.0)\n",
      "Using cached langchain-0.0.350-py3-none-any.whl (809 kB)\n",
      "Using cached langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
      "Using cached langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: langsmith, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.15\n",
      "    Uninstalling langsmith-0.3.15:\n",
      "      Successfully uninstalled langsmith-0.3.15\n",
      "\u001b[33m  WARNING: The script langsmith is installed in '/home/jupyter-st125404/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.45\n",
      "    Uninstalling langchain-core-0.3.45:\n",
      "      Successfully uninstalled langchain-core-0.3.45\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.19\n",
      "    Uninstalling langchain-community-0.3.19:\n",
      "      Successfully uninstalled langchain-community-0.3.19\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.20\n",
      "    Uninstalling langchain-0.3.20:\n",
      "      Successfully uninstalled langchain-0.3.20\n",
      "\u001b[33m  WARNING: The script langchain-server is installed in '/home/jupyter-st125404/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-text-splitters 0.3.6 requires langchain-core<1.0.0,>=0.3.34, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.0.350 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate==0.25.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from accelerate==0.25.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from accelerate==0.25.0) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/tljh/user/lib/python3.12/site-packages (from accelerate==0.25.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/tljh/user/lib/python3.12/site-packages (from accelerate==0.25.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from accelerate==0.25.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from accelerate==0.25.0) (0.29.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from accelerate==0.25.0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/tljh/user/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/tljh/user/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (74.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.25.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.25.0) (4.66.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2024.12.14)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.36.2\n",
      "  Using cached transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "Requirement already satisfied: filelock in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers==4.36.2) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers==4.36.2) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers==4.36.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers==4.36.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.36.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers==4.36.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.36.2) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers==4.36.2) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.36.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.36.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.36.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.36.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.36.2) (2024.12.14)\n",
      "Using cached transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/jupyter-st125404/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.15.2 requires accelerate>=0.34.0, but you have accelerate 0.25.0 which is incompatible.\n",
      "trl 0.15.2 requires transformers>=4.46.0, but you have transformers 4.36.2 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.36.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bitsandbytes==0.41.2 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (0.41.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /opt/tljh/user/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: numpy in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (1.15.1)\n",
      "Requirement already satisfied: nltk in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sentence-transformers==2.2.2) (0.29.3)\n",
      "Requirement already satisfied: filelock in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/tljh/user/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (74.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.5.2)\n",
      "Requirement already satisfied: click in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from torchvision->sentence-transformers==2.2.2) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/lib/python3.12/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.12.14)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.4.1\n",
      "    Uninstalling sentence-transformers-3.4.1:\n",
      "      Successfully uninstalled sentence-transformers-3.4.1\n",
      "Successfully installed sentence-transformers-2.2.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: InstructorEmbedding==1.0.1 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (1.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf==1.23.8 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (1.23.8)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.7 in /home/jupyter-st125404/.local/lib/python3.12/site-packages (from pymupdf==1.23.8) (1.23.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu==1.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[31mERROR: No matching distribution found for faiss-gpu==1.7.2\u001b[0m\u001b[31m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu==1.7.4\n",
      "  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\n",
      "  Installing build dependencies ... \u001bdone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: faiss-cpu\n",
      "  Building wheel for faiss-cpu (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for faiss-cpu \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'faiss._swigfaiss' extension\n",
      "  \u001b[31m   \u001b[0m swigging faiss/faiss/python/swigfaiss.i to faiss/faiss/python/swigfaiss_wrap.cpp\n",
      "  \u001b[31m   \u001b[0m swig -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -DSWIGWORDSIZE64 -module swigfaiss -o faiss/faiss/python/swigfaiss_wrap.cpp faiss/faiss/python/swigfaiss.i\n",
      "  \u001b[31m   \u001b[0m error: command 'swig' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for faiss-cpu\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build faiss-cpu\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (faiss-cpu)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#langchain library\n",
    "!pip install langchain==0.0.350\n",
    "#LLM\n",
    "!pip install accelerate==0.25.0\n",
    "!pip install transformers==4.36.2\n",
    "!pip install bitsandbytes==0.41.2\n",
    "#Text Embedding\n",
    "!pip install sentence-transformers==2.2.2\n",
    "!pip install InstructorEmbedding==1.0.1\n",
    "#vectorstore\n",
    "!pip install pymupdf==1.23.8\n",
    "!pip install faiss-gpu==1.7.2\n",
    "!pip install faiss-cpu==1.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt\n",
    "\n",
    "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)  # Check CUDA version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about my eductional background or work experience, \\n    I'm here to assist you.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    I'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \n",
    "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
    "    Whether it's about my eductional background or work experience, \n",
    "    I'm here to assist you.\n",
    "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "PROMPT\n",
    "#using str.format \n",
    "#The placeholder is defined using curly brackets: {} {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about my eductional background or work experience, \\n    I'm here to assist you.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    My age is 23 years\\n    Question: What is your age?\\n    Answer:\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT.format(\n",
    "    context = \"My age is 23 years\",\n",
    "    question = \"What is your age?\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval\n",
    "\n",
    "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code). \n",
    "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
    "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
    "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
    "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Document Loaders \n",
    "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
    "\n",
    "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
    "\n",
    "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "nlp_docs = 'CV_Tooba_Mehboob.pdf'\n",
    "\n",
    "loader = PyMuPDFLoader(nlp_docs)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Other language(s):\\n  \\nUNDERSTANDING\\nSPEAKING\\nWRITING\\nListening\\nReading\\nSpoken production Spoken interaction\\nENGLISH \\nC2\\nC2\\nC2\\nC2\\nC2\\nLevels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user \\nWeb Technologies Fundamentals - HTML, CSS\\n Node.Js, React.Js\\n Microsoft Oﬃce\\n Zustand\\n React Hooks, React\\nRedux\\n JavaScript\\n Git\\n Machine learning\\n Model training\\n Dataset Building\\n JQuery\\n Email Template\\nMarkup\\n Tailwind\\n Material Tailwind\\n Python \\nMaize Seeds Species Classiﬁcation using Machine Leanring \\n• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\\n• Creating datasets by discarding blurred and duplicate images, resizing images and applying data augmentation on\\nthe selected images.\\n• On these dataset trained ﬁve machine learning models i.e., LeNet, MobileNet, SmallVGG, Random Forest and\\nConvolutional Neural Networks.\\n• Developed a mobile application by selecting Convolutional Neural Network model which gave 92% accuracy.\\nE-Commerce Website \\n• Developed the front-end interface using React.js, resulting in a user-friendly and visually appealing app.\\n• Implemented secure payment processing through integration with the Stripe API, ensuring smooth and secure\\ntransactions for the backend and Database\\n• Tech Used: React, Express.js, MongoDB, REST API, styled-components, Redux Toolkit.\\nCoﬀee-connoiseur \\n• Developed the front-end in Next.js where users can ﬁnd the nearest coﬀee stores based on their location using\\nFoursquare API.\\n• Rendered the data both using SSG and Server side.\\n• Wrote serverless functions, Database used AirTable.\\nSMS Tool Console \\n• Developed voice management module using ReactJS and react bootstrap which includes adding promotional and\\ntransactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.\\n•  Developed frontend for modules on client side which includes dashboard, notices, notes pool, tasks, applications,\\ntime adjustment, shifts planner and payroll.\\n• APIs integration for each module.\\n• State management using Zustand.\\nPromotional Web Pages \\nDIGITAL SKILLS \\nPROJECTS \\n', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Document Transformers\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "doc = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='project on Maize Seeds Species Classiﬁcation using Machine Learning. During my internship at software company, I\\ncontributed to web development projects, gaining practical expertise in ReactJS, NodeJS, NextJS, Express and\\nMongoDB. Noteworthy achievements include development of HR software, SMS Tool Console, Data Pulse and SMS API\\nTester. I am adept at problem-solving, collaborating in team environments, and eﬀectively communicating complex\\ntechnical concepts. I am excited about the prospect of contributing my skills and further advancing my expertise in\\ncomputer technologies.\\n01/06/2023 – 10/07/2024 Peshawar, Pakistan \\nTRAINEE WEB ENGINEER VEEVO TECH', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade transformers sentence-transformers huggingface_hub langchain langchain-community InstructorEmbedding protobuf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Text Embedding Models\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": device}  # Ensure no 'token' argument is passed\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Vector Stores\n",
    "\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate vectorstore\n",
    "vector_path = '../vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vector locally\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents = doc,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "vectordb.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'nlp' #default index\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 retrievers\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling vector from local\n",
    "vector_path = '../vector-store'\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp', #default index\n",
    "    allow_dangerous_deserialization=True\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to use\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Tooba Mehboob \\nDate of birth: 26/02/2002\\n Nationality: Pakistani\\n Gender: Female \\n Phone number: (+92) 3465547722 (Mobile) \\n \\nEmail address: toobamehboob36@gmail.com \\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\n \\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor's I have done\", metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='Girls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='transactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='CGPA: 3.57 out of 4.00\\nFinal grade A \\nThesis Maize seeds species classiﬁcation using Machine Learning \\n02/09/2017 – 29/07/2019 Peshawar, Pakistan \\nHSSC (PRE-ENGINEERING) Agricultural University Public School and College for Girls \\nMarks obtained: 897 out of 1100\\nFinal grade A1 \\n01/04/2015 – 07/07/2017 Peshawar, Pakistan \\nSSC Al-Amanah Youth Academy \\nMarks obtained: 920 out of 1100\\nFinal grade A1 \\nMother tongue(s):  URDU \\nABOUT ME \\nWORK EXPERIENCE\\nEDUCATION AND TRAINING\\nLANGUAGE SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Tooba Mehboob \\nDate of birth: 26/02/2002\\n Nationality: Pakistani\\n Gender: Female \\n Phone number: (+92) 3465547722 (Mobile) \\n \\nEmail address: toobamehboob36@gmail.com \\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\n \\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor's I have done\", metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='CGPA: 3.57 out of 4.00\\nFinal grade A \\nThesis Maize seeds species classiﬁcation using Machine Learning \\n02/09/2017 – 29/07/2019 Peshawar, Pakistan \\nHSSC (PRE-ENGINEERING) Agricultural University Public School and College for Girls \\nMarks obtained: 897 out of 1100\\nFinal grade A1 \\n01/04/2015 – 07/07/2017 Peshawar, Pakistan \\nSSC Al-Amanah Youth Academy \\nMarks obtained: 920 out of 1100\\nFinal grade A1 \\nMother tongue(s):  URDU \\nABOUT ME \\nWORK EXPERIENCE\\nEDUCATION AND TRAINING\\nLANGUAGE SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='transactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='Girls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is my age?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory\n",
    "\n",
    "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
    "\n",
    "You may want to use this class directly if you are managing memory outside of a chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message('hi')\n",
    "history.add_ai_message('Whats up?')\n",
    "history.add_user_message('How are you')\n",
    "history.add_ai_message('I\\'m quite good. How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Memory types\n",
    "\n",
    "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios. \n",
    "- Converstaion Buffer\n",
    "- Converstaion Buffer Window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What variables get returned from memory\n",
    "\n",
    "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converstaion Buffer\n",
    "This memory allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content=\"What's up?\"),\n",
       "  HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm quite good. How about you?\")]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages = True)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer Window\n",
    "- it keeps a list of the interactions of the conversation over time. \n",
    "- it only uses the last K interactions. \n",
    "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chain\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
    "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
    "- it formats the prompt template using the input key values provided (and also memory key values, if available), \n",
    "- it passes the formatted string to LLM and returns the LLM output.\n",
    "\n",
    "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./models\n",
    "# !git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a115c5045f4836a81c470205814926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "\n",
    "model_id = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32,  # Force 32-bit precision to prevent overflow\n",
    "    device_map=\"auto\"  # Auto-detect GPU or CPU\n",
    ")\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Wrap HuggingFace pipeline properly\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# Define RetrievalQA with correct LLM\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  \n",
    "    retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (shared): Embedding(32110, 2048)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32110, 2048)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32110, 2048)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "AutoModel.from_pretrained(\"lmsys/fastchat-t5-3b-v1.0\", cache_dir=\"../models/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
    "\n",
    "- `retriever` : Retriever to use to fetch documents.\n",
    "\n",
    "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
    "\n",
    "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
    "\n",
    "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
    "\n",
    "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
    "\n",
    "- `return_generated_question` : Return the generated question as part of the final result.\n",
    "\n",
    "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "Human:What is your name\n",
      "AI:\n",
      "Human:What is your age?\n",
      "AI:\n",
      "Follow Up Input: Comparing both of them\n",
      "Standalone question:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 69, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human:What is your name\\nAI:\\nHuman:What is your age?\\nAI:',\n",
       " 'question': 'Comparing both of them',\n",
       " 'text': 'Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\nHuman:What is your name\\nAI:\\nHuman:What is your age?\\nAI:\\nFollow Up Input: Comparing both of them\\nStandalone question: What'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Comparing both of them'\n",
    "chat_history = \"Human:What is your name\\nAI:\\nHuman:What is your age?\\nAI:\"\n",
    "\n",
    "question_generator({'chat_history' : chat_history, \"question\" : query})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combine_docs_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about my eductional background or work experience, \\n    I'm here to assist you.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x79b3b95be330>)), document_variable_name='context')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about my eductional background or work experience, \n",
      "    I'm here to assist you.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    CGPA: 3.57 out of 4.00\n",
      "Final grade A \n",
      "Thesis Maize seeds species classiﬁcation using Machine Learning \n",
      "02/09/2017 – 29/07/2019 Peshawar, Pakistan \n",
      "HSSC (PRE-ENGINEERING) Agricultural University Public School and College for Girls \n",
      "Marks obtained: 897 out of 1100\n",
      "Final grade A1 \n",
      "01/04/2015 – 07/07/2017 Peshawar, Pakistan \n",
      "SSC Al-Amanah Youth Academy \n",
      "Marks obtained: 920 out of 1100\n",
      "Final grade A1 \n",
      "Mother tongue(s):  URDU \n",
      "ABOUT ME \n",
      "WORK EXPERIENCE\n",
      "EDUCATION AND TRAINING\n",
      "LANGUAGE SKILLS\n",
      "\n",
      "computer technologies.\n",
      "01/06/2023 – 10/07/2024 Peshawar, Pakistan \n",
      "TRAINEE WEB ENGINEER VEEVO TECH \n",
      "• Web development using main technologies that are ReactJS, JavaScript, JQuery, MongoDB, NodeJS, Express,\n",
      "TailwindCSS, Material Tailwind, NextJS HTML, CSS, Scss.\n",
      "• Responsible for the maintenance of existing products and services.\n",
      "• Responsible for development of new products and development.\n",
      "• Integrate data from various back-end services and databases.\n",
      "• Gather and reﬁne speciﬁcations and requirements based on technical needs.\n",
      "02/09/2019 – 21/09/2023 Peshawar, Pakistan \n",
      "BACHELOR OF SCIENCE IN COMPUTER SCIENCE University of Engineering and Technology \n",
      "CGPA: 3.57 out of 4.00\n",
      "Final grade A\n",
      "\n",
      "• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\n",
      "• Creating datasets by discarding blurred and duplicate images, resizing images and applying data augmentation on\n",
      "the selected images.\n",
      "• On these dataset trained ﬁve machine learning models i.e., LeNet, MobileNet, SmallVGG, Random Forest and\n",
      "Convolutional Neural Networks.\n",
      "• Developed a mobile application by selecting Convolutional Neural Network model which gave 92% accuracy.\n",
      "E-Commerce Website \n",
      "• Developed the front-end interface using React.js, resulting in a user-friendly and visually appealing app.\n",
      "\n",
      "Girls \n",
      "2012 \n",
      "1st Position in Academics – Muhammad Amir Memorial Academy \n",
      "2011 \n",
      "2nd Position in Academics – Muhammad Amir Memorial Academy \n",
      "2010 \n",
      "Good Behaviour – Muhammad Amir Memorial Academy \n",
      "2010 \n",
      "3rd Position in Academics – Muhammad Amir Memorial Academy \n",
      "Organizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \n",
      "Organizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \n",
      "Served as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \n",
      "HONOURS AND AWARDS \n",
      "MANAGEMENT AND LEADERSHIP SKILLS\n",
      "    Question: Study?\n",
      "    Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 794, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='CGPA: 3.57 out of 4.00\\nFinal grade A \\nThesis Maize seeds species classiﬁcation using Machine Learning \\n02/09/2017 – 29/07/2019 Peshawar, Pakistan \\nHSSC (PRE-ENGINEERING) Agricultural University Public School and College for Girls \\nMarks obtained: 897 out of 1100\\nFinal grade A1 \\n01/04/2015 – 07/07/2017 Peshawar, Pakistan \\nSSC Al-Amanah Youth Academy \\nMarks obtained: 920 out of 1100\\nFinal grade A1 \\nMother tongue(s):  URDU \\nABOUT ME \\nWORK EXPERIENCE\\nEDUCATION AND TRAINING\\nLANGUAGE SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       "  Document(page_content='computer technologies.\\n01/06/2023 – 10/07/2024 Peshawar, Pakistan \\nTRAINEE WEB ENGINEER VEEVO TECH \\n• Web development using main technologies that are ReactJS, JavaScript, JQuery, MongoDB, NodeJS, Express,\\nTailwindCSS, Material Tailwind, NextJS HTML, CSS, Scss.\\n• Responsible for the maintenance of existing products and services.\\n• Responsible for development of new products and development.\\n• Integrate data from various back-end services and databases.\\n• Gather and reﬁne speciﬁcations and requirements based on technical needs.\\n02/09/2019 – 21/09/2023 Peshawar, Pakistan \\nBACHELOR OF SCIENCE IN COMPUTER SCIENCE University of Engineering and Technology \\nCGPA: 3.57 out of 4.00\\nFinal grade A', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       "  Document(page_content='• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\\n• Creating datasets by discarding blurred and duplicate images, resizing images and applying data augmentation on\\nthe selected images.\\n• On these dataset trained ﬁve machine learning models i.e., LeNet, MobileNet, SmallVGG, Random Forest and\\nConvolutional Neural Networks.\\n• Developed a mobile application by selecting Convolutional Neural Network model which gave 92% accuracy.\\nE-Commerce Website \\n• Developed the front-end interface using React.js, resulting in a user-friendly and visually appealing app.', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       "  Document(page_content='Girls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''})],\n",
       " 'question': 'Study?',\n",
       " 'output_text': 'I\\'m your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you\\'re curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it\\'s about my eductional background or work experience, \\n    I\\'m here to assist you.\\n    Just let me know what you\\'re wondering about, and I\\'ll do my best to guide you through it!\\n    CGPA: 3.57 out of 4.00\\nFinal grade A \\nThesis Maize seeds species classiﬁcation using Machine Learning \\n02/09/2017 – 29/07/2019 Peshawar, Pakistan \\nHSSC (PRE-ENGINEERING) Agricultural University Public School and College for Girls \\nMarks obtained: 897 out of 1100\\nFinal grade A1 \\n01/04/2015 – 07/07/2017 Peshawar, Pakistan \\nSSC Al-Amanah Youth Academy \\nMarks obtained: 920 out of 1100\\nFinal grade A1 \\nMother tongue(s):  URDU \\nABOUT ME \\nWORK EXPERIENCE\\nEDUCATION AND TRAINING\\nLANGUAGE SKILLS\\n\\ncomputer technologies.\\n01/06/2023 – 10/07/2024 Peshawar, Pakistan \\nTRAINEE WEB ENGINEER VEEVO TECH \\n• Web development using main technologies that are ReactJS, JavaScript, JQuery, MongoDB, NodeJS, Express,\\nTailwindCSS, Material Tailwind, NextJS HTML, CSS, Scss.\\n• Responsible for the maintenance of existing products and services.\\n• Responsible for development of new products and development.\\n• Integrate data from various back-end services and databases.\\n• Gather and reﬁne speciﬁcations and requirements based on technical needs.\\n02/09/2019 – 21/09/2023 Peshawar, Pakistan \\nBACHELOR OF SCIENCE IN COMPUTER SCIENCE University of Engineering and Technology \\nCGPA: 3.57 out of 4.00\\nFinal grade A\\n\\n• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\\n• Creating datasets by discarding blurred and duplicate images, resizing images and applying data augmentation on\\nthe selected images.\\n• On these dataset trained ﬁve machine learning models i.e., LeNet, MobileNet, SmallVGG, Random Forest and\\nConvolutional Neural Networks.\\n• Developed a mobile application by selecting Convolutional Neural Network model which gave 92% accuracy.\\nE-Commerce Website \\n• Developed the front-end interface using React.js, resulting in a user-friendly and visually appealing app.\\n\\nGirls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS\\n    Question: Study?\\n    Answer: Yes'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Study?\"\n",
    "input_document = retriever.get_relevant_documents(query)\n",
    "\n",
    "doc_chain({'input_documents':input_document, 'question':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about my eductional background or work experience, \\n    I'm here to assist you.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x79b3b95be330>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x79b3b95be330>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x79b3b196bd80>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x79b3cb18b8c0>))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about my eductional background or work experience, \n",
      "    I'm here to assist you.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    Tooba Mehboob \n",
      "Date of birth: 26/02/2002\n",
      " Nationality: Pakistani\n",
      " Gender: Female \n",
      " Phone number: (+92) 3465547722 (Mobile) \n",
      " \n",
      "Email address: toobamehboob36@gmail.com \n",
      " Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \n",
      " \n",
      "I am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\n",
      "CSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\n",
      "Redux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\n",
      "me with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor's I have done\n",
      "\n",
      "transactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\n",
      "and groups, and logs.\n",
      "• Bugs ﬁxing in the software.\n",
      "• APIs integration.\n",
      "Data Pulse \n",
      "• Designed front end using HTML, CSS, and JQuery.\n",
      "• Designed dashboard for the software.\n",
      "• Designed analytics page which included 3D charts and graphs.\n",
      "• APIs integration\n",
      "HR Software - Empleado \n",
      "• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\n",
      "dashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\n",
      "applications, leaves planner, notices, notes pool and task planner.\n",
      "\n",
      "Girls \n",
      "2012 \n",
      "1st Position in Academics – Muhammad Amir Memorial Academy \n",
      "2011 \n",
      "2nd Position in Academics – Muhammad Amir Memorial Academy \n",
      "2010 \n",
      "Good Behaviour – Muhammad Amir Memorial Academy \n",
      "2010 \n",
      "3rd Position in Academics – Muhammad Amir Memorial Academy \n",
      "Organizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \n",
      "Organizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \n",
      "Served as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \n",
      "HONOURS AND AWARDS \n",
      "MANAGEMENT AND LEADERSHIP SKILLS\n",
      "\n",
      "Other language(s):\n",
      "  \n",
      "UNDERSTANDING\n",
      "SPEAKING\n",
      "WRITING\n",
      "Listening\n",
      "Reading\n",
      "Spoken production Spoken interaction\n",
      "ENGLISH \n",
      "C2\n",
      "C2\n",
      "C2\n",
      "C2\n",
      "C2\n",
      "Levels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user \n",
      "Web Technologies Fundamentals - HTML, CSS\n",
      " Node.Js, React.Js\n",
      " Microsoft Oﬃce\n",
      " Zustand\n",
      " React Hooks, React\n",
      "Redux\n",
      " JavaScript\n",
      " Git\n",
      " Machine learning\n",
      " Model training\n",
      " Dataset Building\n",
      " JQuery\n",
      " Email Template\n",
      "Markup\n",
      " Tailwind\n",
      " Material Tailwind\n",
      " Python \n",
      "Maize Seeds Species Classiﬁcation using Machine Leanring \n",
      "• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\n",
      "    Question: Who are you by the way?\n",
      "    Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 812, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Who are you by the way?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'I\\'m your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you\\'re curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it\\'s about my eductional background or work experience, \\n    I\\'m here to assist you.\\n    Just let me know what you\\'re wondering about, and I\\'ll do my best to guide you through it!\\n    Tooba Mehboob \\nDate of birth: 26/02/2002\\n Nationality: Pakistani\\n Gender: Female \\n Phone number: (+92) 3465547722 (Mobile) \\n \\nEmail address: toobamehboob36@gmail.com \\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\n \\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor\\'s I have done\\n\\ntransactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.\\n\\nGirls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS\\n\\nOther language(s):\\n  \\nUNDERSTANDING\\nSPEAKING\\nWRITING\\nListening\\nReading\\nSpoken production Spoken interaction\\nENGLISH \\nC2\\nC2\\nC2\\nC2\\nC2\\nLevels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user \\nWeb Technologies Fundamentals - HTML, CSS\\n Node.Js, React.Js\\n Microsoft Oﬃce\\n Zustand\\n React Hooks, React\\nRedux\\n JavaScript\\n Git\\n Machine learning\\n Model training\\n Dataset Building\\n JQuery\\n Email Template\\nMarkup\\n Tailwind\\n Material Tailwind\\n Python \\nMaize Seeds Species Classiﬁcation using Machine Leanring \\n• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\\n    Question: Who are you by the way?\\n    Answer: I',\n",
       " 'source_documents': [Document(page_content=\"Tooba Mehboob \\nDate of birth: 26/02/2002\\n Nationality: Pakistani\\n Gender: Female \\n Phone number: (+92) 3465547722 (Mobile) \\n \\nEmail address: toobamehboob36@gmail.com \\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\n \\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor's I have done\", metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       "  Document(page_content='transactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       "  Document(page_content='Girls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''}),\n",
       "  Document(page_content='Other language(s):\\n  \\nUNDERSTANDING\\nSPEAKING\\nWRITING\\nListening\\nReading\\nSpoken production Spoken interaction\\nENGLISH \\nC2\\nC2\\nC2\\nC2\\nC2\\nLevels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user \\nWeb Technologies Fundamentals - HTML, CSS\\n Node.Js, React.Js\\n Microsoft Oﬃce\\n Zustand\\n React Hooks, React\\nRedux\\n JavaScript\\n Git\\n Machine learning\\n Model training\\n Dataset Building\\n JQuery\\n Email Template\\nMarkup\\n Tailwind\\n Material Tailwind\\n Python \\nMaize Seeds Species Classiﬁcation using Machine Leanring \\n• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.', metadata={'source': 'CV_Tooba_Mehboob.pdf', 'file_path': 'CV_Tooba_Mehboob.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': 'Europass', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'cairo 1.15.12 (http://cairographics.org)', 'creationDate': \"D:20240714105949+02'00\", 'modDate': '', 'trapped': ''})]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Who are you by the way?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2845 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content='I\\'m your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you\\'re curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it\\'s about my eductional background or work experience, \\n    I\\'m here to assist you.\\n    Just let me know what you\\'re wondering about, and I\\'ll do my best to guide you through it!\\n    Tooba Mehboob \\nDate of birth: 26/02/2002\\n Nationality: Pakistani\\n Gender: Female \\n Phone number: (+92) 3465547722 (Mobile) \\n \\nEmail address: toobamehboob36@gmail.com \\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\n \\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor\\'s I have done\\n\\ntransactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.\\n\\nGirls \\n2012 \\n1st Position in Academics – Muhammad Amir Memorial Academy \\n2011 \\n2nd Position in Academics – Muhammad Amir Memorial Academy \\n2010 \\nGood Behaviour – Muhammad Amir Memorial Academy \\n2010 \\n3rd Position in Academics – Muhammad Amir Memorial Academy \\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\nHONOURS AND AWARDS \\nMANAGEMENT AND LEADERSHIP SKILLS\\n\\nOther language(s):\\n  \\nUNDERSTANDING\\nSPEAKING\\nWRITING\\nListening\\nReading\\nSpoken production Spoken interaction\\nENGLISH \\nC2\\nC2\\nC2\\nC2\\nC2\\nLevels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user \\nWeb Technologies Fundamentals - HTML, CSS\\n Node.Js, React.Js\\n Microsoft Oﬃce\\n Zustand\\n React Hooks, React\\nRedux\\n JavaScript\\n Git\\n Machine learning\\n Model training\\n Dataset Building\\n JQuery\\n Email Template\\nMarkup\\n Tailwind\\n Material Tailwind\\n Python \\nMaize Seeds Species Classiﬁcation using Machine Leanring \\n• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\\n    Question: Who are you by the way?\\n    Answer: I'), HumanMessage(content='What is the your age?'), AIMessage(content='I\\'m your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\n    If you\\'re curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it\\'s about my eductional background or work experience, \\n    I\\'m here to assist you.\\n    Just let me know what you\\'re wondering about, and I\\'ll do my best to guide you through it!\\n    Tooba Mehboob \\nDate of birth: 26/02/2002\\n Nationality: Pakistani\\n Gender: Female \\n Phone number: (+92) 3465547722 (Mobile) \\n \\nEmail address: toobamehboob36@gmail.com \\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\n \\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor\\'s I have done\\n\\ncomputer technologies.\\n01/06/2023 – 10/07/2024 Peshawar, Pakistan \\nTRAINEE WEB ENGINEER VEEVO TECH \\n• Web development using main technologies that are ReactJS, JavaScript, JQuery, MongoDB, NodeJS, Express,\\nTailwindCSS, Material Tailwind, NextJS HTML, CSS, Scss.\\n• Responsible for the maintenance of existing products and services.\\n• Responsible for development of new products and development.\\n• Integrate data from various back-end services and databases.\\n• Gather and reﬁne speciﬁcations and requirements based on technical needs.\\n02/09/2019 – 21/09/2023 Peshawar, Pakistan \\nBACHELOR OF SCIENCE IN COMPUTER SCIENCE University of Engineering and Technology \\nCGPA: 3.57 out of 4.00\\nFinal grade A\\n\\ntransactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\nand groups, and logs.\\n• Bugs ﬁxing in the software.\\n• APIs integration.\\nData Pulse \\n• Designed front end using HTML, CSS, and JQuery.\\n• Designed dashboard for the software.\\n• Designed analytics page which included 3D charts and graphs.\\n• APIs integration\\nHR Software - Empleado \\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\napplications, leaves planner, notices, notes pool and task planner.\\n\\n• Implemented secure payment processing through integration with the Stripe API, ensuring smooth and secure\\ntransactions for the backend and Database\\n• Tech Used: React, Express.js, MongoDB, REST API, styled-components, Redux Toolkit.\\nCoﬀee-connoiseur \\n• Developed the front-end in Next.js where users can ﬁnd the nearest coﬀee stores based on their location using\\nFoursquare API.\\n• Rendered the data both using SSG and Server side.\\n• Wrote serverless functions, Database used AirTable.\\nSMS Tool Console \\n• Developed voice management module using ReactJS and react bootstrap which includes adding promotional and\\n    Question: Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n[HumanMessage(content=\\'Who are you by the way?\\'), AIMessage(content=\\'I\\\\\\'m your friendly NLP chatbot named ToobiBot, here to assist anyone with any questions they have about me. \\\\n    If you\\\\\\'re curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\\\n    Whether it\\\\\\'s about my eductional background or work experience, \\\\n    I\\\\\\'m here to assist you.\\\\n    Just let me know what you\\\\\\'re wondering about, and I\\\\\\'ll do my best to guide you through it!\\\\n    Tooba Mehboob \\\\nDate of birth: 26/02/2002\\\\n Nationality: Pakistani\\\\n Gender: Female \\\\n Phone number: (+92) 3465547722 (Mobile) \\\\n \\\\nEmail address: toobamehboob36@gmail.com \\\\n Address: Islamia Colony, Palosi Piran, 25130, Pakistan (Home) \\\\n \\\\nI am a highly motivated computer science graduate with a solid foundation in web technologies which includes HTML,\\\\nCSS, Scss, TailwindCSS, Material Tailwind, JQuery, JavaScript, ReactJS, NodeJS, NextJS, Express, MongoDB, Zustand,\\\\nRedux and API Integrations. My academic journey at University of Engineering and Technology, Peshawar, equipped\\\\nme with a robust skill set, reinforced by hands-on experiences and coursework. During my bachelor\\\\\\'s I have done\\\\n\\\\ntransactional voice messages, accepting and rejecting voices, searching the voices, sending voice to individual\\\\nand groups, and logs.\\\\n• Bugs ﬁxing in the software.\\\\n• APIs integration.\\\\nData Pulse \\\\n• Designed front end using HTML, CSS, and JQuery.\\\\n• Designed dashboard for the software.\\\\n• Designed analytics page which included 3D charts and graphs.\\\\n• APIs integration\\\\nHR Software - Empleado \\\\n• Developed frontend for modules admin side HR software using ReactJS and TailwindCSS which includes\\\\ndashboard, attendance, payroll, notices, forms and approvals, performance management, shift management,\\\\napplications, leaves planner, notices, notes pool and task planner.\\\\n\\\\nGirls \\\\n2012 \\\\n1st Position in Academics – Muhammad Amir Memorial Academy \\\\n2011 \\\\n2nd Position in Academics – Muhammad Amir Memorial Academy \\\\n2010 \\\\nGood Behaviour – Muhammad Amir Memorial Academy \\\\n2010 \\\\n3rd Position in Academics – Muhammad Amir Memorial Academy \\\\nOrganizing Member at event Kaawish - Literary and Debating Society, UET Peshawar \\\\nOrganizer at one day Seminar on \"Cyber Security and Digital Forensics\" by NCCS, UET Peshawar \\\\nServed as Core Member as a Google Developer Student Club for the 2022 - 2023 academic year \\\\nHONOURS AND AWARDS \\\\nMANAGEMENT AND LEADERSHIP SKILLS\\\\n\\\\nOther language(s):\\\\n  \\\\nUNDERSTANDING\\\\nSPEAKING\\\\nWRITING\\\\nListening\\\\nReading\\\\nSpoken production Spoken interaction\\\\nENGLISH \\\\nC2\\\\nC2\\\\nC2\\\\nC2\\\\nC2\\\\nLevels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user \\\\nWeb Technologies Fundamentals - HTML, CSS\\\\n Node.Js, React.Js\\\\n Microsoft Oﬃce\\\\n Zustand\\\\n React Hooks, React\\\\nRedux\\\\n JavaScript\\\\n Git\\\\n Machine learning\\\\n Model training\\\\n Dataset Building\\\\n JQuery\\\\n Email Template\\\\nMarkup\\\\n Tailwind\\\\n Material Tailwind\\\\n Python \\\\nMaize Seeds Species Classiﬁcation using Machine Leanring \\\\n• Collected the samples of diﬀerent varieties of maize seeds and captured image of each seed.\\\\n    Question: Who are you by the way?\\\\n    Answer: I\\')]\\nFollow Up Input: What is the your age?\\nStandalone question: What\\n    Answer: I')]\n",
      "Follow Up Input: What is your work experience?\n",
      "Standalone question:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jupyter-st125404/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 2845, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacity of 10.75 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 9.73 GiB memory in use. Of the allocated memory 9.35 GiB is allocated by PyTorch, and 197.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is your work experience?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprompt_question\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m answer\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/conversational_retrieval/base.py:146\u001b[0m, in \u001b[0;36mBaseConversationalRetrievalChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_history_str:\n\u001b[1;32m    145\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m _run_manager\u001b[38;5;241m.\u001b[39mget_child()\n\u001b[0;32m--> 146\u001b[0m     new_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_history_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     new_question \u001b[38;5;241m=\u001b[39m question\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:550\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    546\u001b[0m         _output_key\n\u001b[1;32m    547\u001b[0m     ]\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    551\u001b[0m         _output_key\n\u001b[1;32m    552\u001b[0m     ]\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_community/llms/huggingface_pipeline.py:267\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:208\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1121\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1118\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1119\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[0;32m-> 1121\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:271\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1673\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1657\u001b[0m         input_ids,\n\u001b[1;32m   1658\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1670\u001b[0m     )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1672\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:2521\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2521\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1246\u001b[0m, in \u001b[0;36mFalconForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1246\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1260\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1122\u001b[0m, in \u001b[0;36mFalconModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1111\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1112\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         output_attentions,\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1122\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:796\u001b[0m, in \u001b[0;36mFalconDecoderLayer.forward\u001b[0;34m(self, hidden_states, alibi, attention_mask, position_ids, layer_past, head_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m     attention_layernorm_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# Self attention.\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_layernorm_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43malibi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnew_decoder_architecture:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:469\u001b[0m, in \u001b[0;36mFalconAttention.forward\u001b[0;34m(self, hidden_states, alibi, attention_mask, position_ids, layer_past, head_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(F, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_dot_product_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# TODO: deprecate this once we add FA2 support in Falcon\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current implementation of Falcon calls `torch.scaled_dot_product_attention` directly, this will be deprecated in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m future in favor of the `BetterTransformer` API. Please install the latest optimum library with `pip install -U optimum` and call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model.to_bettertransformer()` to benefit from `torch.scaled_dot_product_attention` and future performance optimizations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     )\n\u001b[0;32m--> 469\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_layer_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_layer_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacity of 10.75 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 9.73 GiB memory in use. Of the allocated memory 9.35 GiB is allocated by PyTorch, and 197.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "prompt_question = \"What is your work experience?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
